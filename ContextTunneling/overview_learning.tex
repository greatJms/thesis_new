
\myparagraph{A Data-Driven Approach}


We address this challenge with a data-driven approach that
automatically learns a good tunneling heuristic from training data.
To do so, we first define a parameterized heuristic $\heuristic_\Pi$
(where $\Pi$ is a parameter). $\heuristic_\Pi$ takes a program and
returns a relation $\TunnelingRelation$ on methods such that
the relation contains a method pair $(m_1, m_2)$ if the calling
context of $m_1$ is more important than that
of $m_2$. Thus, if $(m_1, m_2) \in \TunnelingRelation$, the analysis
applies context tunneling for $m_2$; that is, $m_2$ inherits the context of
$m_1$ ignoring the current context element. For
the example program, $\heuristic_\Pi$ produces the
relation $\TunnelingRelation = \myset{({\tt id}, {\tt id})}$, which means that tunneling is applied to
{\tt id} when {\tt id} is called from itself. As a result, the
call-site 4, on which {\tt id} is called from {\tt id}, will not
be used as important context elements during analysis.  When {\tt main} calls
{\tt id}, however, the analysis updates the contexts as ordinary since
$({\tt main}, {\tt id}) \not\in \TunnelingRelation$.

The parameter $\Pi$ controls the behavior of the heuristic
$\heuristic_\Pi$.
Following the recent data-driven technique by~\citet{JeJeChOh17}, the
parameter $\Pi$ consists of boolean formulas over
atomic features on methods. We use two boolean formulas $\fprime$ and
$\fsecond$, which describe the sets of methods whose calling contexts
are important and unimportant, respectively.
For example, suppose we are given three atomic features
$\mba = \myset{a_1,a_2,a_3}$, where a feature $a_i : \mbox{Method} \to \myset{\true, \false}$ is a
predicate on methods (e.g. whether the return type of a method is
string, etc) and
assume that the methods {\tt main} and {\tt id} in the example
code have the features as follows:
\[
\begin{array}{llll}
&a_1({\tt main}) = \false, \quad &a_2 ({\tt main}) = \false, \quad &a_3({\tt main}) =
\true \\
&a_1({\tt id}) = \true, \quad &a_2({\tt id}) = \true,  \quad& a_3({\tt id}) = \false
\end{array}
% \mbox{features}({\tt main}) = \myset{a_3}, \qquad \mbox{features}({\tt
%   id}) = \myset{a_1, a_2}.
\]
Then, the following formulas $\fprime$ and $\fsecond$
\[
\fprime = a_1 \land \neg a_3, \qquad \fsecond = a_2 \land \neg a_3
\]
represent the sets of methods as follows:
\[
\db{\fprime} = \myset{{\tt id}}, \qquad \db{\fsecond}=\myset{{\tt id}}.
\]
Given $\Pi = \myset{\fprime, \fsecond}$, the heuristic
$\heuristic_\Pi$ produces the tunneling relation $\TunnelingRelation$
as follows:
\[
\TunnelingRelation = \myset{(m_1,m_2) \mid m_1 \in \db{\fprime} \vee m_2
  \in \db{\fsecond}}.
\]
That is, we apply tunneling if the caller context is important or the
callee context is unimportant.
Thus, the effectiveness of tunneling depends on $\Pi = \myset{\fprime,
  \fsecond}$ and it is the job of the learning algorithm to find
formulas $\fprime$ and $\fsecond$ such that the analysis with
$\heuristic_\Pi$ consistently performs well on a wide range of programs.

\myparagraph{Learning Context Tunneling Heuristics}
\begin{figure}
\begin{multicols}{2}
\begin{lstlisting}
Class A{} Class B{}
Class C{
	static Object id(Object v){
		return v;
	}
	static Object idrec(Object v, int i){
		return i >= 0 ? idrec(v, i-1) : v;
	}	
	static Object id1(Object v){
		return id(v);
	}
	static Object id2(Object v, int i){
		return idrec(v,i);
	}

	public static void main(){
		int i = input();
		A a1 = (A) id(new A());       //Q1
		B b1 = (b) id(new B());       //Q2
		A a2 = (A) id(new A());       //Q3
		B b2 = (b) id(new B());       //Q4
		
		A a3 = (A) id1(new A());      //Q5
		B b3 = (B) id1(new B());      //Q6
		
		A a4 = (A) id2(new A(), i);   //Q7
		B b4 = (B) id2(new B(), i);   //Q8
	}
}
\end{lstlisting}
\end{multicols}
\caption{Extended example code}
\label{fig:overview:new}
\end{figure}
We illustrate how our learning algorithm infers the tunneling relation, more specifically two Boolean formulas $\fprime$ and $\fsecond$. We extended previous example code to have three additional identity functions (i.e., \texttt{id1}, \texttt{id2}, and \texttt{idrec}) and more queries (i.e., Q1 -- Q8) as shown in Figure~\ref{fig:overview:new}. For simplicity, we consider the example code as sole training program, and suppose we are about to learn tunneling heuristic for $\onecallH$ using four atomic features $\afeatures=\myset{a, b, c, d}$. The goal of the learning algorithm is finding good heuristic parameter $\params=\langle \fprime, \fsecond \rangle$ that maximizes analysis precision (i.e., prove all queries) while keeping cost as small as conventional analysis.

Before we begin, we briefly explain a desirable context tunneling relation $\TunnelingRelation$ to prove eight queries Q1 -- Q8 in the example code with $\onecallHT$.
\begin{itemize}
\item {\bf Q1 -- Q4}: Applying conventional $\onecallH$ is enough to prove those queries. In terms of context tunneling, therefore, four {\tt id} invocations in {\tt main} (lines 18 -- 21) should generate context information as usual and hence the desirable tunneling relation $\TunnelingRelation$ shouldn't have $({\tt main}, {\tt id})$ relation in it.
\item {\bf Q5 and Q6}: Passing two {\tt id1} invocations' context to their descendants (i.e., {\tt id}) can prove those two queries because a call-site of {\tt id} (i.e., [10]) has less information gain. In other words, $\TunnelingRelation$ should have $({\tt id1}, {\tt id})$ relation. Note that this inclusion makes analysis to treat {\tt id} invocations differently with regard to their callers. Hence, invocations in line 18 -- 21 are analyzed in conventional way but one in line 10 gets context tunneling.
\item {\bf Q7 and Q8}: {\tt idrec} method calls should inherit context information from their callers in order to prove those two queries. In terms of context tunneling, $\TunnelingRelation$ should include $({\tt id2}, {\tt idrec})$ and $({\tt idrec}, {\tt idrec})$ relations.
\end{itemize}
All in all, $\onecallHT$ can prove all queries in the example under the desirable context tunneling relation $\TunnelingRelation$:
\[
\TunnelingRelation=\myset{({\tt id1}, {\tt id}), ({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}
\]
Remaining of this subsection illustrates how our learning process infers two Boolean formulas $\fprime$ and $\fsecond$ to imply the desirable relations $\TunnelingRelation$.

\paragraph{Sketch of learning} Our learning algorithm begins with learning $\fsecond$, which means callee methods who should inherit context information from their callers instead of generating new ones. After that, our algorithm uses very same procedure to learn $\fprime$ to distinguish caller methods that should propagate their context information to descendants with regard to $\fsecond$. That means, we learn $\fprime$ such that, propagating context information from $m' \in \sem{\fprime}$ to its descendants increases precision even if one of descendant methods $m$ is meant to generate context information because $m \notin \sem{\fsecond}$.


\paragraph{Learning a Single Parameter $\fsecond$} Learning $\fsecond$ starts with setting baseline parameter $\params$ to $\langle \false, \false \rangle$, which means conventional analysis (i.e., $\onecallH$). Using the baseline parameter, our learning algorithm identifies a set of atomic features $W$ who has context tunneling potential. We say an atomic feature $a$ has potential if $\params_a=\langle \false, \fsecond=a \rangle$ makes analysis to prove queries that the baseline analysis can't. Suppose that each atomic feature means methods as follows:
\begin{equation} \label{eq:atoms}
\begin{aligned}
\sem{a}(P) & = & \myset{\texttt{id1}, \texttt{id2}, \texttt{idrec}} & \quad\quad & \sem{b}(P) & = & \myset{\texttt{id}, \texttt{id2}, \texttt{idrec}}\\
\sem{c}(P) & = & \myset{\texttt{id}, \texttt{id1}, \texttt{idrec}} & \quad\quad & \sem{d}(P) & = & \myset{\texttt{id}, \texttt{id1}, \texttt{id2}}
\end{aligned}
\end{equation}

Evaluating each atomic features including the baseline parameter gives following tunneling relations and precisions:
\begin{center}
% $\myset{(main, id), (main, id1), (main, id2), (id1, id), (id2, idrec), (idrec, idrec)}$
\begin{tabular}{c|c|c}
  \hline
  $\fsecond$ & Tunneling Relation $\TunnelingRelation$ & Proven queries\\
  \hline \hline
  $\false$ & $\emptyset$ & Q1, Q2, Q3, Q4 \\
  $a$ & $\myset{({\tt main}, {\tt id1}), ({\tt main}, {\tt id2}), ({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}$ & Q1, Q2, Q3, Q4 \\
  $b$ & $\myset{({\tt main}, {\tt id}), ({\tt main}, {\tt id2}), ({\tt id1}, {\tt id}), ({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}$ & \underline{Q5}, \underline{Q6} \\
  $c$ & $\myset{({\tt main}, {\tt id}), ({\tt main}, {\tt id1}), ({\tt id1}, {\tt id}), ({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}$ & \underline{Q7}, \underline{Q8} \\
  $d$ & $\myset{({\tt main}, {\tt id}), ({\tt main}, {\tt id1}), ({\tt main}, {\tt id2}), ({\tt id1}, {\tt id})}$ & $\emptyset$ \\
  \hline
\end{tabular}
\end{center}
For example, evaluating $\fsecond = \myset{a}$ results same precision with the baseline. Method {\tt id}, which isn't belong to $\TunnelingRelation$, invocations generate context information hence four queries Q1 -- Q4 are provable. For the other queries, it fails to prove because important methods (i.e., {\tt id1} and {\tt id2}) are belong to $\TunnelingRelation$ hence they inherit context information from {\tt main}, which is less informative.

From the evaluation, our algorithm initializes workset $W$ with the features who proved queries except Q1 -- Q4, which are provable by the baseline parameter. We call them ``seed features''. The learning process ends after refining each seed feature in $W$:
\[
W=\myset{b, c}
\]

\paragraph{Refining Seed Feature} Than, our algorithm picks a feature from $W$ with the highest potential, not with the highest precision, and it conservatively refines the chosen feature by conjoining it with the other atomic features. Suppose that we choose $c$ from $W$. Consulting Eq.~\ref{eq:atoms} gives us a feature $d$ because it shares many methods with $c$ than other features, and $c$ becomes $c\land d$ (i.e., applying tunneling for \texttt{id} and \texttt{id1}). Once refined, we check the intermediate formula's precision and cost. Running analysis with the refined parameter gives following result:
\[
F_P(\heuristic_{\langle \false, c \land d \rangle}(P)) : \emptyset
\]
Since it has less precise than before, we drop the last refinement and record it to avoid in future. Suppose the next conservative choice is $a$. The refinement gives us following analysis result:
\[
F_P(\heuristic_{\langle \false, c \land a \rangle}(P)) : Q1, Q2, Q3, Q4, Q7, Q8
\]
The refinement was successful and suppose we continue to conjoin it with $b$. The refined formula $c \land a \land b$ means \texttt{idrec} method only, and evaluating it results same precision as before:
\[
F_P(\heuristic_{\langle \false, c \land a \land b\rangle}(P)) : Q1, Q2, Q3, Q4, Q7, Q8
\]
In this case, our algorithm accepts the refinement only if it makes analysis cheaper than before. Suppose this refinement is the case and proceed to the last refinement, conjoining with $d$. However, this attempt refines the formula too much and results the conventional analysis. Since analysis with our best formula (i.e., $c \land a \land b$) already surpassed it, we reject the refinement and finalize a refinement for the $c$.

Once we have a fully refined conjunction, we update parameter with the conjunction to compare with the baseline parameter. If the updated parameter is more precise and cheaper than the baseline, we set the updated parameter to new baseline and continue to refine next atomic feature in $W$. Otherwise, we discard the conjunction and proceed to next iteration. In this example, $\heuristic_{\langle \false, c \land a \land b\rangle}$ is more precise than the baseline. We assume that it also cheaper than the baseline and proceed to refining next atomic feature in $W$, which is $b$, after updating $\fsecond$ as follows:
\[
\fsecond = c \land a \land b
\]
Refining $b$ takes exactly same steps as for the case of refining $c$, except we have better baseline heuristic from previous iteration. For the sake of simplicity, we skip the details about refining feature $b$ and assume that we've rejected the refinement due to lack of precision. That emptied $W$ means we have $\fsecond$ as follows:
\[
\sem{\fsecond = c \land a \land b} = \myset{\texttt{idrec}}
\]

\paragraph{Learning a Single Parameter $\fprime$}On top of the learned $\fsecond$, our algorithm learns $\fprime$, which means methods who should generate context information and transfer to their descendants, using same procedure as for $\fsecond$. First, we populate a workset $W$ with atomic features who has tunneling potential with regard to the given $\fsecond$. Evaluating potential gives us results as follows;
\begin{center}
% $\myset{({\tt main}, {\tt id}), ({\tt main}, {\tt id1}), ({\tt main}, {\tt id2}), ({\tt id1}, {\tt id}), ({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}$
\begin{tabular}{c|c|c}
  \hline
  $\fprime$ & Tunneling Relation $\TunnelingRelation$ & Proven queries\\
  \hline \hline
  $\false$ & $\myset{({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}$ & Q1, Q2, Q3, Q4, Q7, Q8 \\
  $a$ & $\myset{({\tt id1}, {\tt id}), ({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}$ & Q1, Q2, Q3, Q4, \underline{Q5}, \underline{Q6}, Q7, Q8\\
  $b$ & $\myset{({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}$ & Q1, Q2, Q3, Q4, Q7, Q8 \\
  $c$ & $\myset{({\tt id1}, {\tt id}), ({\tt idrec}, {\tt idrec})}$ & Q1, Q2, Q3, Q4, \underline{Q5}, \underline{Q6} \\
  $d$ & $\myset{({\tt id1}, {\tt id}), ({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}$ & Q1, Q2, Q3, Q4, \underline{Q5}, \underline{Q6}, Q7, Q8 \\
  \hline
\end{tabular}
\end{center}
and features who proved underlined queries comprise $W$:
\[
W=\myset{a, c, d}
\]

\paragraph{Refining Seed Feature} Suppose we choose $c$ to refine. Conservative refinement makes $c$ be $(c \land a)$. Performing analysis with the conjunction as $\fprime$ results as follows:
\[
F_P(\heuristic_{\langle c \land a, c \land a \land b \rangle}(P)) : Q1, Q2, Q3, Q4, Q7, Q8
\]
Assume that this parameter is cheaper than the baseline, we pick another feature to conjoin, which is $d$. The refined conjunction $(c \land a \land d)$ now means method \texttt{id1} only, and gives us following analysis result:
\[
F_P(\heuristic_{\langle c \land a \land d, c \land a \land b \rangle}(P)) : Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8
\]
Now we have parameter to prove all queries in the example code and proceed refinement further to find cheaper solutions if any. However, conjoining the conjunction with $b$ makes the it to mean nothing. We discard the refinement and finalize the refinement for the chosen $c$. Needless to say, the conjunction has enough precision to pass later evaluation against the baseline. For simplicity, we omit further refinements and it gives us two Boolean formulas $\fprime$ and $\fsecond$ as follows:
\[
\begin{array}{c c c}
\sem{\fprime = c \land a \land d} = \myset{\texttt{id1}} &\quad\quad& \sem{\fsecond = c \land a \land b} = \myset{\texttt{idrec}}
\end{array}
\]
Finally, those two learned formulas give us the desirable context tunneling relation $\TunnelingRelation$ as follows:
\[
\TunnelingRelation=\myset{({\tt id1}, {\tt id}), ({\tt id2}, {\tt idrec}), ({\tt idrec}, {\tt idrec})}
\]